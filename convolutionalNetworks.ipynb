{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les réseaux de Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les réseaux de convolution ont été introduits dès la fin des années avec les travaux de Yann LeCun. \n",
    "Ces derniers sont destinés au traitement de l'information organisé sous une forme de tableau 2D. Cette topologie regroupe aussi bien les images que les séries temporelles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette approche fait aujourd'hui l'unanimité pour les problèmes de traitements d'images. Son succès tient à l'ajustement des méthodes de Deep Learning aux spécificités des images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous rappellerons tout d'abord la définition mathématique de l'opération de convolution. Nous expliciterons ensuite l'analogie entre la convolution mathématique et la convolution des réseaux neuronaux. Nous présentenrons alors les spécificités et le formalisme de cette approche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'opération de convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'opération de convolution est une opération bien connue notamment dans les sciences du traitement du signal. C'est cet opérateur qui régit la transformation d'un signal par un opérateur linéaire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathématiquement, l'opération s'écrit comme suit :\n",
    "$$ s(t) = \\int x(a)\\omega(t-a)da $$ \n",
    "\n",
    "Forme qu'on abrège le plus souvent par : \n",
    "$$ s(t) = (x*\\omega)(t) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'ensemble de nos applications, nous travaillons dans le domaine discret, il convient donc d'adopter la notation :\n",
    "    $$ s(t) = \\sum_{a=-\\infty}^{\\infty}x(a)\\omega(t-a)   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, dans nous travaillerons sur des images, soit des données 2D. \n",
    "Il convient alors de préciser l'écriture précédente :\n",
    "\n",
    "$$ S(i,j) = (I*K)(i,j) = \\sum_{m} \\sum_{n} I(m,n)K(i-m,j-n) $$ \n",
    "\n",
    "\n",
    "avec:\n",
    "- $I$ l'entrée\n",
    "- $K$ le kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on peut remarquer que l'inversion réalisée par la convolution n'est utile que pour garantir la commutativité de l'opération. Or, en pratique, cette propriété n'est pas utile en Apprentissage Machine.\n",
    "Par conséquent, un certain nombre de librairies ont plutôt implémenté la *cross-correlation* qui n'inverse pas le kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelles motivations pour les réseaux de convolution ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le succès des réseaux de convolution s'explique par trois propriétés particulières."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans une couche d'un réseau de neurones traditionnels, toutes les unités de l'*input* sont prises en compte pour calculer l'*output*. C'est pourquoi on parle de connexions denses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les réseaux de convolution, la situation est différente. L'idée est ici d'utiliser des *kernels* plus petits que l'*input*. Ces derniers seront consacrés à des tâches bien particulières; ne nécessitant qu'une information locale. Ainsi, même si l'on s'intéresse à une image composée de millons de pixels, il pourrait être pertinent d'utiliser des kernels que de quelques dizaines ou centaines de pixels de bord pour détecter les bordures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette modélisation s'appuie donc sur la nature locale des informations contenues dans une image. Pour reconnaitre une roue, il n'y a toujours besoin de reconnaitre d'abord la voiture.\n",
    "Ce choix permet d'effectuer des gains significatifs sur la mémoire utilisée et sur le nombre de calcul réalisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sparseInteractions](img/sparseConnectivity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notion de partage de paramètres définit la manière dont les paramètres vont être appris. Dans un réseau classique, chaque paramètre est calculé exactement une seule fois : lorsque un neurone particulier considère une entrée particulière. \n",
    "Désormais, avec le *paramater sharing*, les paramètres sont partagés entre les différents neurones. \n",
    "\n",
    "Ainsi, dans une couche consacrée à la détection des bords, deux neurones successifs appliqueront les mêmes paramètres à leurs entrées respectives. Ils sont destinés à détecter des bords, il est donc naturel qu'ils opérent les mêmes opérations sur leurs entrées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce partage permet une économie très importante des puissances de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gifConvolution](https://s1.qwant.com/thumbr/0x0/a/c/ba1e79eb93de2dc3f2891b4b4f1dfc/b_1_q_0_p_0.jpg?u=http%3A%2F%2Fbamos.github.io%2Fdata%2F2016-08-09%2Fpadding_strides.gif&q=0&b=1&p=0&a=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'un des avantages du parameter sharing est qu'il rend le réseau insensible aux translations dans l'espace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'indépendance aux translations est un aspect fondamental des réseaux de conovolution. Il permet de vraiment se concentrer sur la présence d'un item plutôt que sur sa localisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pooling](img/pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field of View\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut ici adopter une vision plus globale de notre réseau. En effet, le pooling et le stride amènent les couches supérieures à percevoir une zone plus grande de l'image. \n",
    "\n",
    "En effet, au niveau $n$, le pooling résume les informations contenues dans un certain nombre de valeurs, `4` si nous reprenons l'exemple précédent.\n",
    "La couche $n+1$ convoluera les valeurs contenues dans un certain espace, par exemple un carré `2x2`. \n",
    "\n",
    "\n",
    "Par conséquent la couche $n+1$ travaillera sur le résumé des informations de la couche précédente. Son filtre est de taille `2x2` au niveau $n+1$, mais il représente une taille `4x4` au niveau $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![receiptiveField](https://cdn-images-1.medium.com/max/2000/1*KFX5mWoRMfMme2jngak8wg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation des différentes fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalisme mathématiques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple rapide d'implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ici présenter une implémentation d'une couche de convolution, en utilisant la librairie <a href=index.html >TensorFlow</a>. \n",
    "\n",
    "La déclaration d'une couche peut tenir en seulement quelques lignes, comme nous pouvons le voir ci-dessous : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "\"\"\" Layer 1 \"\"\"\n",
    "W_conv1_1 = tf.Variable(tf.truncated_normal([3, 3, 3, 64],stddev=0.02))\n",
    "b_conv1_1 = tf.Variable(tf.constant(0.0,[64])\n",
    "conv1_1 = tf.nn.conv2d(image, W_conv1_1, strides=[1, s, s, 1], padding='SAME') + b_conv1_1\n",
    "relu1_1 = tf.nn.relu(conv1_1)\n",
    "pool1 = tf.nn.max_pool(relu1_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La 1ère ligne définit la forme de la couche. Nous définissons alors dans l'ordre :\n",
    "- la taille de la fenetre de convolution : ici `3x3` \n",
    "- la largeur de l'entrée : ici pour `3`, pour chaque catégorie de couleur\n",
    "- la largeur de la sortie : ici `64`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la 2ème ligne, nous définissons le nombre de biais, qui est égal à la profondeur de la sortie, soit `64`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la 3ème ligne, nous définissons l'opération de convolution, en précisant l'image à filtrer, le filtre et les biais à utiliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la 4ème ligne, nous définissons la fonction d'activation, ici la fonction `relu` classique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la 5ème ligne, nous définissons la fonction `pool` à utiliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple d'architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
