{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Différents algorithmes importants \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classification est un problème du traitement d'images où l'algorithme va reconnaitre la principale composante de l'image. \n",
    "\n",
    "C'est cette catégorie de problèmes que voulait traiter <a href==http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf> le réseau proposé par Yann Lecun </a>. Une des application était de résoudre le défi MNIST : soit la classification des nombres `0` à `9` écrits à la main."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![leNet](img/leNet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'architecture utilisé est maintenant une architecture incontournable. \n",
    "\n",
    "Le réseau est consituté de 2 couches de convolution, couplées avec des couches de pooling.\n",
    "Les 3 dernières couches sont des couches de neurones densément connectés qui permettent de conclure sur la classe la plus présente dans l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème de classification a rapidement été complété par le problème de segmentation sémantique. \n",
    "\n",
    "Le but est de détecter les différents objets, les segmenter, puis les identifier. \n",
    "\n",
    "![semanticSegmentation](img/semanticSegmentation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet devient alors insuffisant. Il est en effet incapable d'associer à chaque pixel une classe. Il faut donc changer de paradigme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un des premiers réseaux à apporter une solution était le <a href=https://arxiv.org/pdf/1411.4038.pdf> Fully Convolution Network </a> (FCN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce dernier apportait plusieurs contibutions. \n",
    "\n",
    "Tout d'abord l'idée est de remplacer la couche finale densément connectée du réseau, par une couche convolutionnelle. Cela permet d'obtenir une carte de résultat et plus seulement une catégorie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ![FCNimage](http://blog.qure.ai/assets/images/segmentation-review/FCN%20-%20illustration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais pour obtenir des cartes de résultat pertinentes, il faut résoudre le problème de la transformation au cours des convolutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons vu en effet que les couches de convolution transformaient l'image initiale en un contenu de plus haut niveau mais moins bien localisé. Plus concrétement, le réseau va traiter un ensemble de pixels qui définisse un chat pour en déduire la présence d'un objet chat. Cet objet est une analyse haut niveau de l'image mais sa place est inconnue.\n",
    "\n",
    "Cette caractrétique des CNN découle de la pyramide des 'field of view'. \n",
    "Les FCN éliminent ce problème grâce à **l'upsampling**.\n",
    "\n",
    "Une première approche pour augmenter la résolution d'une image est d'interpoler les pixels voisins. Le pixel rajouté est alors une somme pondéré des pixels voisins.\n",
    "C'est cette même approche qui est utilisé ici. A la différence que c'est le réseau même qui apprendra à réaliser l'interpolation au travers de couches particulières, appelées **deconvolutions layers**.\n",
    "Une telle structure permet notamment au réseau d'apprendre les interpolations non linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le [U-Net](https://arxiv.org/pdf/1505.04597.pdf) se penche sur le même problème que les **FCN** avec une amélioration significative sur le processus de **upsampling**.\n",
    "\n",
    "L'augmentation de la résolution s'opère ici d'une part grâce aux **deconvolutions layers** mais aussi grâce aux **coarse connections**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UNetimage](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réseau se répartit désormais en 2 parties.\n",
    "\n",
    "La branche gauche du réseau réalise des opérations de convolutions classiques. Celles-ci vont permettre d'extraire de l'image les composantes sémantiques; *sans* information de localisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le rôle de la branche de droite est de resituer sur une image de dimension approximativement identique à l'image de départ, l'emplacement des différents objets. \n",
    "Ce travail sera réalisé par des couches de déconvolution, comme précédemment. \n",
    "\n",
    "La nouveauté consiste dans le fait que chaque couche de déconvolution est suivie d'une couche de convolution classique, fusionnat :\n",
    "- le résultat interpolé de la couche précédente \n",
    "- le résultat issue de la couche symétrique sur le coté gauche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce phénomène est notamment illustré par l'image précédente\n",
    "\n",
    "On observe tout au long de la partie gauche une modification de la taille des tenseurs. Intiallement de taille `572x572x1`, ces derniers acquièrent à la fin une taille de `28x28x1024` pour le tenseur $T_{0}$.\n",
    "\n",
    "On observe bien ici l'apparition des élèments sémantiques au détriment de l'information de localisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_{0}$ est alors interpolé en un tenseur $T_{1}$ de dimensions `56x56x512`. On s'attend donc à ce que la couche d'interpolation replace plus finement les informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutefois, pour corriger son travail, nous allons fusionner $T_{1}$ avec le résultat du niveau symétrique de la branche gauche, le tenseur $T_{-1}$. $T_{-1}$ porte l'information que le réseau a extrait à la résolution `56x56`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons alors un tenseur de dimensiosn ` 1024x56x65` qui sera transformé après deux convolutions en un tenseur `512x52x52`, mêlant au mieux les informations locales à cette résolution et les informations sémantiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répeter ce processus permettra de reconstituer une image finale segmentée sémantiquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons à présent nous pencher sur un nouveau problème de traitement d'images : la labelisation. Ce dernier désigne la tâche de détecter et placer précisément un élèment au sein d'une image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CPMimage](https://github.com/shihenw/convolutional-pose-machines-release/raw/master/testing/python/figures/teaser-github.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple ci-dessus, il est par exemple question de placer correctement les différentes parties du corps (main, coude, épaule,...) et d'en déduire les différents membres de la personne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce problème est intimement lié au problème de segmentation sémantique. Il est également nécessaire de concilier compréhension sémantique de l'image et conservation de la taille de l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais nous soulevons ici une série de nouvelles problématiques. L'algorithme doit en effet être capable de gérer la présence et l'abscence des différents points à détecter ainsi que d'être capable de situer un élément vis à vis des autres.\n",
    "\n",
    "En effet, si nous souhaitons différencier la main droite, de la main gauche, il est nécessaire que l'algorithme replace ce point vis à vis du corps entier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
